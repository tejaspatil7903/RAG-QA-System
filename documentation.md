# ğŸ§  AI-Powered PDF Q&A System using LangChain & Mistral-7B

## ğŸ“Œ Overview
This project implements a smart Question Answering (QA) system that reads PDF files and answers user queries using only the document's content. It leverages Retrieval-Augmented Generation (RAG) with Mistral-7B to ensure accurate and grounded responses.

---

## ğŸ§© Problem Statement
Reading large PDFs like research papers, manuals, or legal documents is time-consuming. Users often need specific answers without going through hundreds of pages.

---

## ğŸ’¡ Solution
Using LangChainâ€™s document loading and retrieval tools, the system breaks the PDF into chunks, embeds them with HuggingFace embeddings, stores them in a Chroma vector database, and retrieves relevant sections to answer user queries through a Mistral-7B instruct model.

---

## âš™ï¸ Architecture

- **PDF Loader**: `PyPDFLoader` (LangChain)
- **Text Splitter**: `RecursiveCharacterTextSplitter`
- **Embeddings**: HuggingFace (`all-MiniLM-L6-v2`)
- **Vector Store**: ChromaDB
- **LLM**: Mistral-7B-Instruct (via `langchain-openai`)
- **Prompt Template**: Custom instruction to restrict answers to context only
- **Chain**: RAG using `create_retrieval_chain`

---

## ğŸ§ª Example

**Input Question**: *"What are encoder and decoder tasks?"*  
**Output**: Accurate explanation extracted only from `attention.pdf`, ignoring irrelevant or external data.

---

## âœ… Key Features

- Pure context-based Q&A
- Works with any PDF
- Fast retrieval and inference
- Ready for Streamlit/web integration

---

## ğŸ› ï¸ Technologies

- Python, LangChain
- Mistral-7B, HuggingFace
- Chroma VectorDB
- dotenv for API key management

---

## ğŸ‘¨â€ğŸ’» Author

**Tejas Vinod Patil**  
ğŸ“§ tejasvpatil03@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/tejasvpatil7903)  
ğŸ”— [GitHub](https://github.com/tejaspatil7903/pdf-rag-qa)

---

## ğŸ”— GitHub

[github.com/tejaspatil7903/pdf-rag-qa](https://github.com/tejaspatil7903/RAG-QA-System)
